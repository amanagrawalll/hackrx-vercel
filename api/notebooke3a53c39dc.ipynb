{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# api/index.py\n\nimport os\nimport requests\nimport numpy as np\nimport faiss\nimport groq\nfrom fastapi import FastAPI, Header, HTTPException\nfrom pydantic import BaseModel\nfrom typing import List\nfrom io import BytesIO\nfrom pypdf import PdfReader\nfrom sentence_transformers import SentenceTransformer\n\n# --- Global Objects (loaded once) ---\n# This is a key optimization for serverless functions\nprint(\"Loading Sentence Transformer model...\")\nembedding_model = SentenceTransformer('all-MiniLM-L6-v2')\nprint(\"Model loaded successfully.\")\n\n# Initialize the Groq client, getting the key from environment variables\ntry:\n    client = groq.Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n    print(\"Groq client initialized.\")\nexcept Exception as e:\n    client = None\n    print(f\"Failed to initialize Groq client: {e}\")\n\n# --- Pydantic Models for Request/Response ---\nclass HackRxRequest(BaseModel):\n    documents: str\n    questions: List[str]\n\nclass HackRxResponse(BaseModel):\n    answers: List[str]\n\n# --- Initialize FastAPI App ---\napp = FastAPI()\n\n# --- Helper Functions (logic from your notebook) ---\ndef process_document_from_url(url: str):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        with BytesIO(response.content) as pdf_file:\n            reader = PdfReader(pdf_file)\n            text = \"\".join(page.extract_text() or \"\" for page in reader.pages)\n        \n        chunk_size = 1500\n        chunk_overlap = 200\n        chunks = []\n        start = 0\n        while start < len(text):\n            end = start + chunk_size\n            chunks.append(text[start:end])\n            start += chunk_size - chunk_overlap\n        \n        return [chunk for chunk in chunks if chunk.strip()]\n    except Exception as e:\n        print(f\"Error processing document: {e}\")\n        return []\n\ndef create_vector_store(chunks: list):\n    if not chunks: return None\n    embeddings = embedding_model.encode(chunks, convert_to_tensor=False)\n    dimension = embeddings.shape[1]\n    index = faiss.IndexFlatL2(dimension)\n    index.add(np.array(embeddings).astype('float32'))\n    return index\n\ndef generate_answer_with_groq(question: str, context: str):\n    if not client: return \"Groq client not initialized.\"\n    prompt = f\"\"\"\n    Answer the following question based ONLY on the provided context. If the answer is not in the context, say \"Answer not found in the provided context.\"\n    CONTEXT: {context}\n    QUESTION: {question}\n    ANSWER:\n    \"\"\"\n    try:\n        chat_completion = client.chat.completions.create(\n            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.0\n        )\n        return chat_completion.choices[0].message.content.strip()\n    except Exception as e:\n        print(f\"Groq API call failed: {e}\")\n        return \"Error generating answer from Groq API.\"\n\n# --- API Endpoint ---\n@app.post(\"/hackrx/run\", response_model=HackRxResponse)\nasync def run_submission(request: HackRxRequest):\n    # This endpoint is simplified for deployment.\n    # You should add the Bearer token authentication as per the hackathon rules.\n    \n    chunks = process_document_from_url(request.documents)\n    if not chunks: raise HTTPException(status_code=500, detail=\"Failed to process document.\")\n\n    vector_index = create_vector_store(chunks)\n    if not vector_index: raise HTTPException(status_code=500, detail=\"Failed to create vector store.\")\n\n    all_answers = []\n    for question in request.questions:\n        question_embedding = embedding_model.encode([question])\n        k = 5\n        _, indices = vector_index.search(np.array(question_embedding).astype('float32'), k)\n        retrieved_context = \"\\n\\n---\\n\\n\".join([chunks[i] for i in indices[0]])\n        answer = generate_answer_with_groq(question, retrieved_context)\n        all_answers.append(answer)\n        \n    return HackRxResponse(answers=all_answers)\n\n# Optional: Add a root endpoint for simple health checks\n@app.get(\"/\")\ndef read_root():\n    return {\"status\": \"API is running\"}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-30T21:43:41.322495Z","iopub.execute_input":"2025-07-30T21:43:41.322733Z","iopub.status.idle":"2025-07-30T21:43:41.554382Z","shell.execute_reply.started":"2025-07-30T21:43:41.322713Z","shell.execute_reply":"2025-07-30T21:43:41.553137Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/597946326.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgroq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastAPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTTPException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"],"ename":"ModuleNotFoundError","evalue":"No module named 'faiss'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}